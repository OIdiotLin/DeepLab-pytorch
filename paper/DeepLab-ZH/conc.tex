\section{Conclusion}
Our proposed ``DeepLab'' system re-purposes networks trained
on image classification to the task of semantic segmentation by applying the `atrous convolution' with upsampled filters for dense feature extraction. We further extend it to atrous spatial pyramid pooling, which encodes objects as well as image context at multiple scales. To produce semantically accurate predictions and detailed segmentation maps along object boundaries, we also combine ideas from deep convolutional neural networks and fully-connected conditional random fields. Our experimental results show that the
proposed method significantly advances the state-of-art in several challenging
datasets, including PASCAL VOC 2012 semantic image segmentation benchmark, PASCAL-Context, PASCAL-Person-Part, and Cityscapes datasets.

\section*{Acknowledgments}
This work was partly supported by the ARO 62250-CS, FP7-RECONFIG, FP7-MOBOT, and H2020-ISUPPORT EU projects. We gratefully acknowledge the support of NVIDIA Corporation with the donation of GPUs used for this research.

%It combines ideas from deep convolutional neural networks and fully-connected conditional random fields, yielding a novel method able to produce semantically accurate predictions and detailed segmentation maps, while being computationally efficient. Our experimental results show that the
%proposed method significantly advances the state-of-art in several challenging
%datasets, including PASCAL VOC 2012 semantic image segmentation benchmark, PASCAL-Context,
%PASCAL-Person-Part, and Cityscapes datasets.
