\section{Related Work}

过去十年里，大多数成功的语义分割系统都依赖于人工特征与平面分类器的结合，例如 Boosting \cite{TuB10,shotton2009textonboost}, 随机森林 \cite{shotton2008semantic}, 支持向量机 \cite{FulkersonVS09}。通过结合来自上下文 \cite{carreira2012semantic} 和结构化预测技术 \cite{he2004multiscale,ladicky2009associative,carreira2012cpmc,krahenbuhl2011efficient} 的更丰富的信息，语义分割系统已经实现了实质性的改进，但是这些系统的性能一直受到特征的有限表现能力的约束。在过去几年里，深度学习在计算机视觉方向上的突破从图像分类很快转移到了语义分割。由于这个任务涉及到边界分割与物体分类，因此，其核心问题在于如何组合这两个子任务。

用于语义分割的第一类基于 DCNN 的系统通常采用自下而上的图像分割级联，然后再对划分区域使用 DCNN 进行分类。例如，边界框和被其框住的区域 \cite{arbelaez2014multiscale, Uijlings13} 被同时输入给 DCNN 用于区域分类 \cite{girshick2014rcnn, hariharan2014simultaneous}，以将形状信息结合到分类过程中。类似地，\cite{mostajabi2014feedforward} 的作者靠的是图片的超像素表达。尽管这些方法可以从良好分割所带来的明显边界中受益，但它们也无法从其任何错误中恢复。

第二类依赖于使用卷积计算的 DCNN 特征进行密集图像标记，并与独立获得的分割结合起来。首先是 \cite{farabet2013learning} 以多重分辨率使用 DCNN，然后使用分割树来平滑化分类结果。最近，\cite{hariharan2014hypercolumns} 提出使用跳跃层并连接 DCNN 中计算出的特征以进行像素分类。此外，\cite{dai2014convolutional} 提出利用候选区域集合计算特征图。这些工作仍采用与DCNN 分类器结果分离的分段算法，因此有可能导致过早的决策。

第三类直接使用 DCNN 进行密集的像素级分类，这样能避免分段决策。\cite{long2014fully, eigen2014predicting} 的无分段方法以完全卷积的方式直接将 DCNN 应用于整个图像，将 DCNN 的最后全连接层转换为卷积层。为了处理引言中提到的空间定位问题，\cite{long2014fully} 对特征的得分图进行上采样和连接，而 \cite{eigen2014predicting} 通过将粗略结果传给另一个 DCNN，从而细化预测结果。我们的工作建立在这些工作的基础上，并且如引言中所述通过控制特征分辨率来扩展它们，引入多尺度池化技术并将全连接的 CRF \cite{krahenbuhl2011efficient} 集成在 DCNN 之上。我们发现这会导致明显更好的分割结果，尤其是沿着物体边界。DCNN 与 CRF 的组合使用并非史无前例，但是已有的研究工作中仅仅尝试了 locally-connected 的 CRF 模型。具体而言，\cite{cogswell2014combining} 使用 CRFs 作为基于 DCNN 的重排序系统的建议方法，\cite{farabet2013learning} 将超像素看做是本地成对 CRF 的节点，并使用图形分割进行离散推理。因此，他们的模型受到超像素计算中的错误或忽略的长远依赖的限制。然而，我们的方法将每个像素视为由 DCNN 接收的唯一的 CRF 节点。值得强调的是，我们采用的全连接 CRF 模型使用高斯 CRF 捕捉长远依赖关系 \cite{krahenbuhl2011efficient}，同时，这个模型也适用于快速平均场推断。我们注意到，对于传统的图像分割任务，\cite{geiger1991parallel, geiger1991common, kokkinos2008computational} 已经广泛研究了平均场推断方法，但这些老旧的模型通常仅限于短程连接，难以捕获长程关系。在独立工作中， \cite{bell2014material} 使用非常类似于密集连接的 CRF 模型来细化针对材料分类问题的 DCNN 的结果。然而，\cite{bell2014material} 的 DCNN 模块仅通过稀疏点监督训练，而不是每个像素。

由于本研究工作的初代版本已公开发布 \cite{chen2014semantic}，图像语义分割领域已经取得了巨大的进展。多个研究小组都有着重大的突破进展，显著地提高了 PASCAL VOC 2012 的基线，这也反映了基准测试排行榜\footnote{\url{http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6}} \cite{papandreou2015weakly, zheng2015conditional, dai2015boxsup, noh2015learning, liu2015semantic, lin2015efficient, chen2015attention, chen2015semantic}上水平之高。有趣的是，大多数表现最佳的方法都采用了我们 DeepLab 系统的一两个关键要素：（1）通过空洞卷积进行高效密集特征提取和（2）通过全连接 CRF 对原始DCNN分数的细化。我们在下面概述了一些最重要、最有趣的进展。

\newcommand{\mycomment}[1]{}
\mycomment{
	A key difference compared to \cite{long2014fully} lies in the way we produce
	feature maps at the original image resolution: They use a sequence of
	deconvolutional layers \cite{zeiler2014visualizing}, while we use a combination
	of atrous convolution and bilinear interpolation, resulting in a significantly
	simpler system that explicitly handles the signal downsampling issue, requires
	fewer parameters, and is easier to train.
}

大量相关工作中使用了 \textit{端到端训练结构化预测} 的方法。虽然我们使用 CRF 作为后处理方法，但在 \cite{zheng2015conditional, chen2014learning, schwing2015fully, liu2015semantic, lin2015efficient} 中，研究者已经成功地进行了 DCNN 与 CRF 的联合学习。特别是 \cite{zheng2015conditional, schwing2015fully} 展开了 CRF 的平均场推断，将整个系统转化为可端到端训练的前馈网络，而 \cite{liu2015semantic} 使用带有可学习滤波器的卷积层近似了密集 CRF 一轮平均场推断迭代 \cite{krahenbuhl2011efficient}。\cite{lin2015efficient, chandra2016fast} 使用 DCNN 学习 CRF 的成对点关系，它以繁重的计算为代价提升了模型的准度。\cite{chen2015semantic} 使用更快的域变换模块 \cite{GastalOliveira2011DomainTransform} 替换平均场推断中的双边滤波模块，以提升运算速度降低内存占用。而 \cite{bertasius2015high, kokkinos2016pushing} 将语义分割与边缘检测算法结合起来。

许多论文中使用了 \textit{弱监督训练}，放宽了像素级语义注释可用于整个训练集的假设 \cite{pinheiro2014weakly, papandreou2015weakly, pathakICCV15ccnn, hong2015decoupled}，取得了比弱监督训练 pre-DCNN 更好的结果 \cite{vezhnevets2011weakly}。在另一个研究领域，\cite{hariharan2014simultaneous, liang2015proposal} 追求实例细分，共同解决对象检测和语义分割。

我们称为 \textit{空洞卷积} 的技术源于计算小波变换的 ``algorithme \`a trous'' \cite{holschneider1989real}。我们建议感兴趣的读者朋友引用 \cite{fowler2005redundant} 来获得小波变换的早期文献资料。空洞卷积也与多速率信号处理中的 ``noble identities'' 密切相关，它也是基于输入信号与滤波器采样率的函数 \cite{vaidyanathan1990multirate}。空洞卷积概念是我们在 \cite{papandreou2014untangling} 中首次提出的。同样的操作后来被称之为 \textit{扩张卷积} \cite{yu2015multi}，基于对应操作中包含上采样（\cite{holschneider1989real} 也称为 扩张）这一事实。为了在 DCNNs 中获取更为密集的特征，许多研究者也曾使用过相同的操作 \cite{giusti2013fast, sermanet2013overfeat, papandreou2014untangling}。除了提升分辨率之外，空洞卷积允许我们扩大滤波器的感受野以包含更大的上下文，我们在 \cite{chen2014semantic} 中发现这是有益的。这种方法已被 \cite{yu2015multi} 进一步提升，他使用一系列空洞卷积层来聚合多尺度上下文。我们提出的用于捕获多尺度物体和上下文的空洞空间金字塔池化方法也采用具有不同采样率的多个空洞卷积层，但是，我们是并行而非串行使用。有趣的是，空洞卷积也被运用于更广泛的任务，例如物体检测 \cite{liu2015ssd,dai2016rfcn}、实例分割 \cite{dai2016instance}、视觉问答 \cite{chen2015abc}、光流系统 \cite{sevilla2016optical} 等。

我们还表明，正如预期所料，集成到 DeepLab 中的更高级的图像分类 DCNNs 可以带来更好的结果（如 \cite{he2015deep} 的 ResNet）， \cite{wu2016high} 也观察到了这一点。
